{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Classifying Images of Clothing",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/judemoon/dl_tensorflow/blob/master/Copy_of_Classifying_Images_of_Clothing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "punL79CN7Ox6"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "_ckMIh7O7s6D",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "vasWnqRgy1H4",
        "colab": {}
      },
      "source": [
        "#@title MIT License\n",
        "#\n",
        "# Copyright (c) 2017 François Chollet\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a\n",
        "# copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
        "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
        "# DEALINGS IN THE SOFTWARE."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jYysdyb-CaWM"
      },
      "source": [
        "# Classifying Images of Clothing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S5Uhzt6vVIB2"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l03c01_classifying_images_of_clothing.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l03c01_classifying_images_of_clothing.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FbVhjPpzn6BM"
      },
      "source": [
        "In this tutorial, we'll build and train a neural network to classify images of clothing, like sneakers and shirts.\n",
        "\n",
        "It's okay if you don't understand everything. This is a fast-paced overview of a complete TensorFlow program, with explanations along the way. The goal is to get the general sense of a TensorFlow project, not to catch every detail.\n",
        "\n",
        "This guide uses [tf.keras](https://www.tensorflow.org/guide/keras), a high-level API to build and train models in TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H0tMfX2vR0uD"
      },
      "source": [
        "## Install and import dependencies\n",
        "\n",
        "We'll need [TensorFlow Datasets](https://www.tensorflow.org/datasets/), an API that simplifies downloading and accessing datasets, and provides several sample datasets to work with. We're also using a few helper libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P7mUJVqcINSM",
        "colab": {}
      },
      "source": [
        "!pip install -U tensorflow_datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dzLKpmZICaWN",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_FxXYSCXGQqQ",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  # Use the %tensorflow_version magic if in colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1UbK0Uq7GWaO",
        "colab": {}
      },
      "source": [
        "# Import TensorFlow Datasets\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "# Helper libraries\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "590z76KRGtKk",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yR0EdgrLCaWR"
      },
      "source": [
        "## Import the Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DLdCchMdCaWQ"
      },
      "source": [
        "This guide uses the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset, which contains 70,000 grayscale images in 10 categories. The images show individual articles of clothing at low resolution (28 $\\times$ 28 pixels), as seen here:\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
        "         alt=\"Fashion MNIST sprite\" width=\"600\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>Figure 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST samples</a> (by Zalando, MIT License).<br/>&nbsp;\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n",
        "Fashion MNIST is intended as a drop-in replacement for the classic [MNIST](http://yann.lecun.com/exdb/mnist/) dataset—often used as the \"Hello, World\" of machine learning programs for computer vision. The MNIST dataset contains images of handwritten digits (0, 1, 2, etc) in an identical format to the articles of clothing we'll use here.\n",
        "\n",
        "This guide uses Fashion MNIST for variety, and because it's a slightly more challenging problem than regular MNIST. Both datasets are relatively small and are used to verify that an algorithm works as expected. They're good starting points to test and debug code.\n",
        "\n",
        "We will use 60,000 images to train the network and 10,000 images to evaluate how accurately the network learned to classify images. You can access the Fashion MNIST directly from TensorFlow, using the [Datasets](https://www.tensorflow.org/datasets) API:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7MqDQO0KCaWS",
        "colab": {}
      },
      "source": [
        "dataset, metadata = tfds.load('fashion_mnist', as_supervised=True, with_info=True)\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4mlW2KB6T8I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "26f0aa99-6aca-4222-8429-473d83757f08"
      },
      "source": [
        "metadata"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='fashion_mnist',\n",
              "    version=3.0.0,\n",
              "    description='Fashion-MNIST is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.',\n",
              "    homepage='https://github.com/zalandoresearch/fashion-mnist',\n",
              "    features=FeaturesDict({\n",
              "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
              "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
              "    }),\n",
              "    total_num_examples=70000,\n",
              "    splits={\n",
              "        'test': 10000,\n",
              "        'train': 60000,\n",
              "    },\n",
              "    supervised_keys=('image', 'label'),\n",
              "    citation=\"\"\"@article{DBLP:journals/corr/abs-1708-07747,\n",
              "      author    = {Han Xiao and\n",
              "                   Kashif Rasul and\n",
              "                   Roland Vollgraf},\n",
              "      title     = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning\n",
              "                   Algorithms},\n",
              "      journal   = {CoRR},\n",
              "      volume    = {abs/1708.07747},\n",
              "      year      = {2017},\n",
              "      url       = {http://arxiv.org/abs/1708.07747},\n",
              "      archivePrefix = {arXiv},\n",
              "      eprint    = {1708.07747},\n",
              "      timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},\n",
              "      biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-07747},\n",
              "      bibsource = {dblp computer science bibliography, https://dblp.org}\n",
              "    }\"\"\",\n",
              "    redistribution_info=,\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ag9JGpy6Z_F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "02cc350e-836e-47c1-cf28-44376b87d728"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test': <DatasetV1Adapter shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>,\n",
              " 'train': <DatasetV1Adapter shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARrXXvjG6njL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d833fff3-f6a7-49ff-b4e2-a8c2e15d536f"
      },
      "source": [
        "dataset['test']"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t9FDsUlxCaWW"
      },
      "source": [
        "Loading the dataset returns metadata as well as a *training dataset* and *test dataset*.\n",
        "\n",
        "* The model is trained using `train_dataset`.\n",
        "* The model is tested against `test_dataset`.\n",
        "\n",
        "The images are 28 $\\times$ 28 arrays, with pixel values in the range `[0, 255]`. The *labels* are an array of integers, in the range `[0, 9]`. These correspond to the *class* of clothing the image represents:\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Label</th>\n",
        "    <th>Class</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>0</td>\n",
        "    <td>T-shirt/top</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>Trouser</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>2</td>\n",
        "    <td>Pullover</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>3</td>\n",
        "    <td>Dress</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>4</td>\n",
        "    <td>Coat</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>5</td>\n",
        "    <td>Sandal</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>6</td>\n",
        "    <td>Shirt</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>7</td>\n",
        "    <td>Sneaker</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>8</td>\n",
        "    <td>Bag</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>9</td>\n",
        "    <td>Ankle boot</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "Each image is mapped to a single label. Since the *class names* are not included with the dataset, store them here to use later when plotting the images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IjnLH5S2CaWx",
        "colab": {}
      },
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal',      'Shirt',   'Sneaker',  'Bag',   'Ankle boot']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Brm0b_KACaWX"
      },
      "source": [
        "### Explore the data\n",
        "\n",
        "Let's explore the format of the dataset before training the model. The following shows there are 60,000 images in the training set, and 10000 images in the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MaOTZxFzi48X",
        "colab": {}
      },
      "source": [
        "num_train_examples = metadata.splits['train'].num_examples\n",
        "num_test_examples = metadata.splits['test'].num_examples\n",
        "print(\"Number of training examples: {}\".format(num_train_examples))\n",
        "print(\"Number of test examples:     {}\".format(num_test_examples))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ES6uQoLKCaWr"
      },
      "source": [
        "## Preprocess the data\n",
        "\n",
        "The value of each pixel in the image data is an integer in the range `[0,255]`. For the model to work properly, these values need to be normalized to the range `[0,1]`. So here we create a normalization function, and then apply it to each image in the test and train datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nAsH3Zm-76pB",
        "colab": {}
      },
      "source": [
        "def normalize(images, labels):\n",
        "  images = tf.cast(images, tf.float32)\n",
        "  images /= 255\n",
        "  return images, labels\n",
        "\n",
        "# The map function applies the normalize function to each element in the train\n",
        "# and test datasets\n",
        "norm_train_dataset =  train_dataset.map(normalize)\n",
        "norm_test_dataset  =  test_dataset.map(normalize)\n",
        "\n",
        "# The first time you use the dataset, the images will be loaded from disk\n",
        "# Caching will keep them in memory, making training faster\n",
        "train_dataset =  train_dataset.cache()\n",
        "test_dataset  =  test_dataset.cache()\n",
        "\n",
        "norm_train_dataset = norm_train_dataset.cache()\n",
        "norm_test_dataset = norm_test_dataset.cache()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lIQbEiJGXM-q"
      },
      "source": [
        "### Explore the processed data\n",
        "\n",
        "Let's plot an image to see what it looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zEeOuHl_DTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for image, label in test_dataset.take(1):\n",
        "  print(image)\n",
        "  #print(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GCFXLRWC6r8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b57f82c3-7234-4e44-cff8-81cf91ac193c"
      },
      "source": [
        "image.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([28, 28, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfg_KgP-CWIr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8f17d28-8905-4dab-838c-7a4b72df3530"
      },
      "source": [
        "image.numpy().reshape((28,28)).shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oSzE9l7PjHx0",
        "colab": {}
      },
      "source": [
        "# Take a single image, and remove the color dimension by reshaping\n",
        "for image, label in test_dataset.take(1):\n",
        "  break\n",
        "image = image.numpy().reshape((28,28))\n",
        "\n",
        "# Plot the image - voila a piece of fashion clothing\n",
        "plt.figure()\n",
        "plt.imshow(image, cmap=plt.cm.binary)\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ee638AlnCaWz"
      },
      "source": [
        "Display the first 25 images from the *training set* and display the class name below each image. Verify that the data is in the correct format and we're ready to build and train the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oZTImqg_CaW1",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "i = 0\n",
        "for (image, label) in test_dataset.take(25):\n",
        "    image = image.numpy().reshape((28,28))\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(image, cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[label])\n",
        "    i += 1\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "59veuiEZCaW4"
      },
      "source": [
        "## Build the model\n",
        "\n",
        "Building the neural network requires configuring the layers of the model, then compiling the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Gxg1XGm0eOBy"
      },
      "source": [
        "### Setup the layers\n",
        "\n",
        "The basic building block of a neural network is the *layer*. A layer extracts a representation from the data fed into it. Hopefully, a series of connected layers results in a representation that is meaningful for the problem at hand.\n",
        "\n",
        "Much of deep learning consists of chaining together simple layers. Most layers, like `tf.keras.layers.Dense`, have internal parameters which are adjusted (\"learned\") during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9ODch-OFCaW4",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gut8A_7rCaW6"
      },
      "source": [
        "This network has three layers:\n",
        "\n",
        "* **input** `tf.keras.layers.Flatten` — This layer transforms the images from a 2d-array of 28 $\\times$ 28 pixels, to a 1d-array of 784 pixels (28\\*28). Think of this layer as unstacking rows of pixels in the image and lining them up. This layer has no parameters to learn, as it only reformats the data.\n",
        "\n",
        "* **\"hidden\"** `tf.keras.layers.Dense`— A densely connected layer of 128 neurons. Each neuron (or node) takes input from all 784 nodes in the previous layer, weighting that input according to hidden parameters which will be learned during training, and outputs a single value to the next layer.\n",
        "\n",
        "* **output** `tf.keras.layers.Dense` — A 10-node *softmax* layer, with each node representing a class of clothing. As in the previous layer, each node takes input from the 128 nodes in the layer before it. Each node weights the input according to learned parameters, and then outputs a value in the range `[0, 1]`, representing the probability that the image belongs to that class. The sum of all 10 node values is 1.\n",
        "\n",
        "\n",
        "### Compile the model\n",
        "\n",
        "Before the model is ready for training, it needs a few more settings. These are added during the model's *compile* step:\n",
        "\n",
        "\n",
        "* *Loss function* — An algorithm for measuring how far the model's outputs are from the desired output. The goal of training is this measures loss.\n",
        "* *Optimizer* —An algorithm for adjusting the inner parameters of the model in order to minimize loss.\n",
        "* *Metrics* —Used to monitor the training and testing steps. The following example uses *accuracy*, the fraction of the images that are correctly classified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lhan11blCaW7",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qKF6uW-BCaW-"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "First, we define the iteration behavior for the train dataset:\n",
        "1. Repeat forever by specifying `dataset.repeat()` (the `epochs` parameter described below limits how long we perform training).\n",
        "2. The `dataset.shuffle(60000)` randomizes the order so our model cannot learn anything from the order of the examples.\n",
        "3. And `dataset.batch(32)` tells `model.fit` to use batches of 32 images and labels when updating the model variables.\n",
        "\n",
        "Training is performed by calling the `model.fit` method:\n",
        "1. Feed the training data to the model using `train_dataset`.\n",
        "2. The model learns to associate images and labels.\n",
        "3. The `epochs=5` parameter limits training to 5 full iterations of the training dataset, so a total of 5 * 60000 = 300000 examples.\n",
        "\n",
        "(Don't worry about `steps_per_epoch`, the requirement to have this flag will soon be removed.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o_Dp8971McQ1",
        "colab": {}
      },
      "source": [
        "# Warning: run this code block only one time, otherwise, input_shape error will occur during the fitting\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataset = train_dataset.repeat().shuffle(num_train_examples).batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "norm_train_dataset = norm_train_dataset.repeat().shuffle(num_train_examples).batch(BATCH_SIZE)\n",
        "norm_test_dataset = norm_test_dataset.batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xvwvpA64CaW_",
        "colab": {}
      },
      "source": [
        "model.fit(norm_train_dataset, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W3ZVOhugCaXA"
      },
      "source": [
        "As the model trains, the loss and accuracy metrics are displayed. This model reaches an accuracy of about 0.88 (or 88%) on the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oEw4bZgGCaXB"
      },
      "source": [
        "## Evaluate accuracy\n",
        "\n",
        "Next, compare how the model performs on the test dataset. Use all examples we have in the test dataset to assess accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VflXLEeECaXC",
        "colab": {}
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(norm_test_dataset, steps=math.ceil(num_test_examples/32))\n",
        "print('Accuracy on test dataset:', test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yWfgsmVXCaXG"
      },
      "source": [
        "As it turns out, the accuracy on the test dataset is smaller than the accuracy on the training dataset. This is completely normal, since the model was trained on the `train_dataset`. When the model sees images it has never seen during training, (that is, from the `test_dataset`), we can expect performance to go down. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xsoS7CPDCaXH"
      },
      "source": [
        "## Make predictions and explore\n",
        "\n",
        "With the model trained, we can use it to make predictions about some images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ccoz4conNCpl",
        "colab": {}
      },
      "source": [
        "for test_images, test_labels in test_dataset.take(1):\n",
        "  test_images = test_images.numpy()\n",
        "  test_labels = test_labels.numpy()\n",
        "  predictions = model.predict(test_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gl91RPhdCaXI",
        "colab": {}
      },
      "source": [
        "predictions.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x9Kk1voUCaXJ"
      },
      "source": [
        "Here, the model has predicted the label for each image in the testing set. Let's take a look at the first prediction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3DmJEUinCaXK",
        "colab": {}
      },
      "source": [
        "predictions[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-hw1hgeSCaXN"
      },
      "source": [
        "A prediction is an array of 10 numbers. These describe the \"confidence\" of the model that the image corresponds to each of the 10 different articles of clothing. We can see which label has the highest confidence value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qsqenuPnCaXO",
        "colab": {}
      },
      "source": [
        "np.argmax(predictions[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E51yS7iCCaXO"
      },
      "source": [
        "So the model is most confident that this image is a shirt, or `class_names[6]`. And we can check the test label to see this is correct:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sd7Pgsu6CaXP",
        "colab": {}
      },
      "source": [
        "test_labels[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ygh2yYC972ne"
      },
      "source": [
        "We can graph this to look at the full set of 10 class predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DvYmmrpIy6Y1",
        "colab": {}
      },
      "source": [
        "def plot_image(i, predictions_array, true_labels, images):\n",
        "  predictions_array, true_label, img = predictions_array[i], true_labels[i], images[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  \n",
        "  plt.imshow(img[...,0], cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "  \n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array[i], true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1]) \n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  \n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d4Ov9OFDMmOD"
      },
      "source": [
        "Let's look at the 0th image, predictions, and prediction array. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HV5jw-5HwSmO",
        "colab": {}
      },
      "source": [
        "i = 0\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions, test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions, test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ko-uzOufSCSe",
        "colab": {}
      },
      "source": [
        "i = 12\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions, test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions, test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kgdvGD52CaXR"
      },
      "source": [
        "Let's plot several images with their predictions. Correct prediction labels are blue and incorrect prediction labels are red. The number gives the percent (out of 100) for the predicted label. Note that it can be wrong even when very confident. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hQlnbqaw2Qu_",
        "colab": {}
      },
      "source": [
        "# Plot the first X test images, their predicted label, and the true label\n",
        "# Color correct predictions in blue, incorrect predictions in red\n",
        "num_rows = 5\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, predictions, test_labels, test_images)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  plot_value_array(i, predictions, test_labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R32zteKHCaXT"
      },
      "source": [
        "Finally, use the trained model to make a prediction about a single image. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yRJ7JU7JCaXT",
        "colab": {}
      },
      "source": [
        "# Grab an image from the test dataset\n",
        "img = test_images[0]\n",
        "\n",
        "print(img.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vz3bVp21CaXV"
      },
      "source": [
        "`tf.keras` models are optimized to make predictions on a *batch*, or collection, of examples at once. So even though we're using a single image, we need to add it to a list:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lDFh5yF_CaXW",
        "colab": {}
      },
      "source": [
        "# Add the image to a batch where it's the only member.\n",
        "img = np.array([img])\n",
        "\n",
        "print(img.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EQ5wLTkcCaXY"
      },
      "source": [
        "Now predict the image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o_rzNSdrCaXY",
        "colab": {}
      },
      "source": [
        "predictions_single = model.predict(img)\n",
        "\n",
        "print(predictions_single)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6Ai-cpLjO-3A",
        "colab": {}
      },
      "source": [
        "plot_value_array(0, predictions_single, test_labels)\n",
        "_ = plt.xticks(range(10), class_names, rotation=45)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cU1Y2OAMCaXb"
      },
      "source": [
        "`model.predict` returns a list of lists, one for each image in the batch of data. Grab the predictions for our (only) image in the batch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2tRmdq_8CaXb",
        "colab": {}
      },
      "source": [
        "np.argmax(predictions_single[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YFc2HbEVCaXd"
      },
      "source": [
        "And, as before, the model predicts a label of 6 (shirt)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-KtnHECKZni_"
      },
      "source": [
        "# Exercises\n",
        "\n",
        "Experiment with different models and see how the accuracy results differ. In particular change the following parameters:\n",
        "*   Set training epochs set to 1\n",
        "*   Number of neurons in the Dense layer following the Flatten one. For example, go really low (e.g. 10) in ranges up to 512 and see how accuracy changes\n",
        "*   Add additional Dense layers between the Flatten and the final `Dense(10)`, experiment with different units in these layers\n",
        "*   Don't normalize the pixel values, and see the effect that has\n",
        "\n",
        "\n",
        "Remember to enable GPU to make everything run faster (Runtime -> Change runtime type -> Hardware accelerator -> GPU).\n",
        "Also, if you run into trouble, simply reset the entire environment and start from the beginning:\n",
        "*   Edit -> Clear all outputs\n",
        "*   Runtime -> Reset all runtimes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_wD6Vb9KP-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(hidden1_num=128, hidden2_num=128, hidden2=False):\n",
        "\n",
        "  # Setup the layers\n",
        "  if hidden2:\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.Dense(hidden1_num, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(hidden2_num, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "    ])\n",
        "\n",
        "  else:\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.Dense(hidden1_num, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "    ])\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1z9AodqLEjX",
        "colab_type": "text"
      },
      "source": [
        "## Set training epochs set to 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jB8PukOKLDPy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4bf06428-a1ea-4a2b-c4c2-713f2fe32113"
      },
      "source": [
        "model_v2 = build_model()\n",
        "\n",
        "# Train the model\n",
        "# The epochs=1 parameter limits training to 1 full iteration of the training dataset, so a total of 60000 examples.\n",
        "model_v2.fit(norm_train_dataset, epochs=1, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 1875 steps\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 1.6788 - accuracy: 0.7919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa610476198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WIIYx5IIfwF0",
        "colab": {}
      },
      "source": [
        "# Evaluate accuracy\n",
        "test_loss, test_accuracy = model_v2.evaluate(norm_test_dataset, steps=math.ceil(num_test_examples/BATCH_SIZE))\n",
        "print('Accuracy on test dataset:', test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRyqaAjUQkV-",
        "colab_type": "text"
      },
      "source": [
        "Restarting runtime resolved the issue with flatten_2_input dimensions. It seems that flatten function change is inplace in the dataset.\n",
        "\n",
        "After changing epochs from 5 to 1, the accuracy decreased from 0.8687 to 0.7019 for train dataset and from 0.8355 to 0.8280 for test dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmK4WjSZGofI",
        "colab_type": "text"
      },
      "source": [
        "## Change Number of neurons in the Dense layer from 128 to 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V_hX9pjGyuK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "47a6d546-1ea5-4374-c010-27528837fe4b"
      },
      "source": [
        "model_v3 = build_model(10)\n",
        "\n",
        "# Train the model\n",
        "model_v3.fit(norm_train_dataset, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 1875 steps\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.7954 - accuracy: 0.6910\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.7037 - accuracy: 0.7669\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6796 - accuracy: 0.7897\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6268 - accuracy: 0.8420\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6203 - accuracy: 0.8478\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa61034ee10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpU52XwLHGQK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "033d2932-8270-4a42-e272-7000e72ec5cc"
      },
      "source": [
        "# Evaluate accuracy\n",
        "test_loss, test_accuracy = model_v3.evaluate(norm_test_dataset, steps=math.ceil(num_test_examples/BATCH_SIZE))\n",
        "print('Accuracy on test dataset:', test_accuracy)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 1.6328 - accuracy: 0.8326\n",
            "Accuracy on test dataset: 0.8326\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jevOlzKuHFK8",
        "colab_type": "text"
      },
      "source": [
        "After changing the hidden layer neuron number from 128 to 10, the accuracy changed from 0.8687 to 0.8478 for train dataset and from 0.8355 to 0.8326 for test dataset.\n",
        "\n",
        "## Change Number of neurons in the Dense layer from 128 to 512"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_EQNkV-IzGv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "5dac76c1-b661-4398-8e41-1420d92b64a0"
      },
      "source": [
        "model_v4 = build_model(512)\n",
        "\n",
        "# Train the model\n",
        "model_v4.fit(norm_train_dataset, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 1875 steps\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.7158 - accuracy: 0.7481\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6733 - accuracy: 0.7881\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6190 - accuracy: 0.8422\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6070 - accuracy: 0.8546\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6022 - accuracy: 0.8588\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa6101dbd30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyEFNfIDPWUu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "26c8d1db-8245-46ff-aa5b-63b2b4e5c459"
      },
      "source": [
        "# Evaluate accuracy\n",
        "model_v4.evaluate(norm_test_dataset, steps=math.ceil(num_test_examples/BATCH_SIZE))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 1.6277 - accuracy: 0.8323\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.627653985739516, 0.8323]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXAwkqo_USIt",
        "colab_type": "text"
      },
      "source": [
        "## Add 2nd hidden dense layer with 128 neurons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9WcaJqkUkON",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e2751941-5c08-4cf3-c56f-7926cc5e3840"
      },
      "source": [
        "model_v5 = build_model(hidden2=True)\n",
        "\n",
        "# Train the model\n",
        "model_v5.fit(norm_train_dataset, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 1875 steps\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6889 - accuracy: 0.7769\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6298 - accuracy: 0.8316\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6173 - accuracy: 0.8437\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6059 - accuracy: 0.8553\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6029 - accuracy: 0.8578\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa5f82ddbe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cPc6YUHU0Kk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5e9abb19-05d7-42a3-aa1b-a018c7894398"
      },
      "source": [
        "# Evaluate accuracy\n",
        "model_v5.evaluate(norm_test_dataset, steps=math.ceil(num_test_examples/BATCH_SIZE))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 1.6114 - accuracy: 0.8501\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.6113796447412656, 0.8501]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzSckFshVDwU",
        "colab_type": "text"
      },
      "source": [
        "## Add 2nd hidden dense layer with 50 neurons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_jGY19jVPy3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e4d8bcdd-7e4c-430e-8d8a-badef95279a3"
      },
      "source": [
        "model_v6 = build_model(hidden2_num=50, hidden2=True)\n",
        "\n",
        "# Train the model\n",
        "model_v6.fit(norm_train_dataset, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 1875 steps\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6694 - accuracy: 0.7981\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6248 - accuracy: 0.8368\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6134 - accuracy: 0.8477\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6022 - accuracy: 0.8589\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6013 - accuracy: 0.8594\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa5f83b8da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJoOhrWoVPng",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8033f208-6952-4cc4-a5ce-bbebd9704547"
      },
      "source": [
        "# Evaluate accuracy\n",
        "model_v6.evaluate(norm_test_dataset, steps=math.ceil(num_test_examples/BATCH_SIZE))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 1.6143 - accuracy: 0.8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.6143450893152256, 0.847]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He5fe40HV6Yd",
        "colab_type": "text"
      },
      "source": [
        "## Set 1st hidden layer neuron to 512 and 2nd hidden layer neuron to 128"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXBDuKCbV6sL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "606d8be2-9f5a-4e70-d893-029119223a5d"
      },
      "source": [
        "model_v7 = build_model(hidden1_num=512, hidden2_num=128, hidden2=True)\n",
        "\n",
        "# Train the model\n",
        "model_v7.fit(norm_train_dataset, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 1875 steps\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.7140 - accuracy: 0.7483\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6869 - accuracy: 0.7732\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6623 - accuracy: 0.7980\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6274 - accuracy: 0.8333\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6188 - accuracy: 0.8418\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa5e2758588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iakhlpx1V6-T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ca820cd2-6390-4b9a-8718-4e4960665278"
      },
      "source": [
        "# Evaluate accuracy\n",
        "model_v7.evaluate(norm_test_dataset, steps=math.ceil(num_test_examples/BATCH_SIZE))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 1.6333 - accuracy: 0.8282\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.6333180128956755, 0.8282]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPPquo_OXVV9",
        "colab_type": "text"
      },
      "source": [
        "## Use data without normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMy0nRtjXVw3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "b8db671d-eeba-404c-f89f-08993d13a7fb"
      },
      "source": [
        "model_v8 = build_model()\n",
        "\n",
        "# Train the model\n",
        "# Use train_dataset instead of norm_train_dataset\n",
        "model_v8.fit(train_dataset, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 1875 steps\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3594 - accuracy: 0.1017\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 2.3626 - accuracy: 0.0985\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3615 - accuracy: 0.0997\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3608 - accuracy: 0.1004\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3604 - accuracy: 0.1007\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa5e273ce48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxaRQs1xXVqZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1f1b27f6-0f0d-4123-8d9d-47037f2f8ddf"
      },
      "source": [
        "# Evaluate accuracy\n",
        "# Use test_dataset instead of norm_test_dataset\n",
        "model_v8.evaluate(test_dataset, steps=math.ceil(num_test_examples/BATCH_SIZE))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 7ms/step - loss: 2.3611 - accuracy: 0.1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.361110233270322, 0.1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLeI2EjOcLzh",
        "colab_type": "text"
      },
      "source": [
        "## Exercise Summary\n",
        "The modifications on hidden layers and epochs did not impact much on the accuracy, but the data normalization had a huge impact on the accuracy.\n",
        "\n",
        "model version |\tmodification | accuracy on train |\taccuracy on test\n",
        "--- | --- | --- | ---\n",
        "model |\toriginal | 0.8683 | 0.8355\n",
        "model_v2 | Set training epochs set to 1\t| 0.7919 | 0.828\n",
        "model_v3 |\tChange Number of neurons in the Dense layer from 128 to 10 | 0.8478 | 0.8326\n",
        "model_v4 |\tChange Number of neurons in the Dense layer from 128 to 512 |0.8588 | 0.8323\n",
        "model_v5 |\tAdd 2nd hidden dense layer with 128 neurons | 0.8578 | 0.8501\n",
        "model_v6 |\tAdd 2nd hidden dense layer with 50 neurons | 0.8594 | 0.847\n",
        "model_v7 |\tSet 1st hidden layer neuron to 512 and 2nd hidden layer neuron to 128 |\t0.8418 | 0.8282\n",
        "model_v8 |\tUse data without normalization | 0.1007 | 0.1"
      ]
    }
  ]
}